{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b04edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from time import time\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.cuda.amp import autocast as autocast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a61166",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络  \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # output: 64 x 16 x 16\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # output: 128 x 8 x 8\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) # output: 256 x 4 x 4\n",
    "        )\n",
    "        # 全连接层\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30182018",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model = Net()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2)\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346959b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(\"./data\", train=True, download=True, transform=train_transform)\n",
    "test_data = datasets.CIFAR10(\"./data\", train=False, download=True, transform=test_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)#求每行的最大就是最有可能的类别\n",
    "    num_correct = (pred_label == label).sum().float()\n",
    "    return num_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    t1 = time()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model = model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):# im,label为一批数据，也就是64个样本\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        #with autocast(): \n",
    "        output = model(images)\n",
    "        # loss = F.cross_entropy(output, labels)\n",
    "        loss = criterion(output ,labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.float()\n",
    "        train_acc += get_acc(output,labels)    \n",
    "    scheduler.step()\n",
    "    t2 = time()\n",
    "    print(\"Spend Time: %s\" % (t2 - t1))\n",
    "    print(\"Train Accuracy: %s\" % (train_acc/len(train_loader)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6785b071",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Half",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     e_float16 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(a_float32, b_float32)\n\u001b[0;32m      9\u001b[0m     f_float16 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(d_float32, e_float16)\n\u001b[1;32m---> 10\u001b[0m g_float32 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_float32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_float16\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Half"
     ]
    }
   ],
   "source": [
    "# 使用tensor.dtype查看数据类型\n",
    "a_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "b_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "c_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "d_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "\n",
    "with autocast():\n",
    "    e_float16 = torch.mm(a_float32, b_float32)\n",
    "    f_float16 = torch.mm(d_float32, e_float16)\n",
    "g_float32 = torch.mm(d_float32, f_float16)#报错\n",
    "# g_float32 = torch.mm(d_float32, f_float16.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a8bb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(a_float32.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4894204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
